import os
import tempfile
import time
from typing import Optional
from pathlib import Path

from fastapi import FastAPI, HTTPException
from fastapi.responses import FileResponse, JSONResponse, StreamingResponse
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field
import uvicorn
import struct

from indextts.infer import IndexTTS

# åˆå§‹åŒ– FastAPI åº”ç”¨
app = FastAPI(
    title="IndexTTS API",
    description="IndexTTS è¯­éŸ³åˆæˆ HTTP æ¥å£",
    version="1.0.0"
)

# æ·»åŠ  CORS ä¸­é—´ä»¶ï¼Œå…è®¸è·¨åŸŸè¯·æ±‚
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# å…¨å±€å˜é‡å­˜å‚¨æ¨¡å‹å®ä¾‹
tts_model: Optional[IndexTTS] = None

# é¢„è®¾çš„å‚è€ƒéŸ³é¢‘æ–‡ä»¶åˆ—è¡¨
REFERENCE_AUDIO_FILES = [
    "/mnt/f/project/fish-speech/source/boke-male.mp3",
    # å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ æ›´å¤šå‚è€ƒéŸ³é¢‘æ–‡ä»¶
]


# Pydantic æ¨¡å‹å®šä¹‰
class SynthesizeRequest(BaseModel):
    text: str = Field(..., description="è¦åˆæˆçš„æ–‡æœ¬")
    reference_audio_index: int = Field(default=0, description="å‚è€ƒéŸ³é¢‘åºå· (ä»0å¼€å§‹)")
    use_fast_inference: bool = Field(default=False, description="æ˜¯å¦ä½¿ç”¨å¿«é€Ÿæ¨ç†")
    verbose: bool = Field(default=False, description="æ˜¯å¦è¾“å‡ºè¯¦ç»†æ—¥å¿—")
    max_text_tokens_per_sentence: int = Field(default=120, description="æ¯å¥è¯çš„æœ€å¤§tokenæ•°")
    # ç”Ÿæˆå‚æ•°
    do_sample: bool = Field(default=True, description="æ˜¯å¦ä½¿ç”¨é‡‡æ ·")
    top_p: float = Field(default=0.95, description="top_p é‡‡æ ·å‚æ•°")
    top_k: int = Field(default=30, description="top_k é‡‡æ ·å‚æ•°")
    temperature: float = Field(default=1.2, description="æ¸©åº¦å‚æ•°")
    length_penalty: float = Field(default=0.0, description="é•¿åº¦æƒ©ç½š")
    num_beams: int = Field(default=3, description="æŸæœç´¢æ•°é‡")
    repetition_penalty: float = Field(default=10.0, description="é‡å¤æƒ©ç½š")
    max_mel_tokens: int = Field(default=600, description="æœ€å¤§mel tokenæ•°é‡")
    # å¿«é€Ÿæ¨ç†ä¸“ç”¨å‚æ•°
    sentences_bucket_max_size: int = Field(default=2, description="åˆ†å¥åˆ†æ¡¶çš„æœ€å¤§å®¹é‡")


class SimpleSynthesizeRequest(BaseModel):
    text: str = Field(..., description="è¦åˆæˆçš„æ–‡æœ¬")
    reference_audio_index: int = Field(default=0, description="å‚è€ƒéŸ³é¢‘åºå· (ä»0å¼€å§‹)")


class StreamSynthesizeRequest(BaseModel):
    text: str = Field(..., description="è¦åˆæˆçš„æ–‡æœ¬")
    reference_audio_index: int = Field(default=0, description="å‚è€ƒéŸ³é¢‘åºå· (ä»0å¼€å§‹)")
    verbose: bool = Field(default=False, description="æ˜¯å¦è¾“å‡ºè¯¦ç»†æ—¥å¿—")
    max_text_tokens_per_sentence: int = Field(default=120, description="æ¯å¥è¯çš„æœ€å¤§tokenæ•°")
    # ç”Ÿæˆå‚æ•°
    do_sample: bool = Field(default=True, description="æ˜¯å¦ä½¿ç”¨é‡‡æ ·")
    top_p: float = Field(default=0.95, description="top_p é‡‡æ ·å‚æ•°")
    top_k: int = Field(default=30, description="top_k é‡‡æ ·å‚æ•°")
    temperature: float = Field(default=1.2, description="æ¸©åº¦å‚æ•°")
    length_penalty: float = Field(default=0.0, description="é•¿åº¦æƒ©ç½š")
    num_beams: int = Field(default=3, description="æŸæœç´¢æ•°é‡")
    repetition_penalty: float = Field(default=10.0, description="é‡å¤æƒ©ç½š")
    max_mel_tokens: int = Field(default=600, description="æœ€å¤§mel tokenæ•°é‡")


def initialize_model():
    """åˆå§‹åŒ– IndexTTS æ¨¡å‹"""
    global tts_model
    try:
        print("æ­£åœ¨åˆå§‹åŒ– IndexTTS æ¨¡å‹...")
        tts_model = IndexTTS(
            cfg_path="checkpoints/config.yaml",
            model_dir="checkpoints",
            is_fp16=True,
            use_cuda_kernel=False
        )
        print("IndexTTS æ¨¡å‹åˆå§‹åŒ–å®Œæˆ!")
    except Exception as e:
        print(f"æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
        raise e


async def _synthesize_speech_core(request: SynthesizeRequest):
    """è¯­éŸ³åˆæˆæ ¸å¿ƒé€»è¾‘"""
    if tts_model is None:
        raise HTTPException(status_code=500, detail="æ¨¡å‹æœªåŠ è½½")
    
    if not request.text.strip():
        raise HTTPException(status_code=400, detail="æ–‡æœ¬ä¸èƒ½ä¸ºç©º")
    
    # éªŒè¯å‚è€ƒéŸ³é¢‘åºå·
    if request.reference_audio_index < 0 or request.reference_audio_index >= len(REFERENCE_AUDIO_FILES):
        raise HTTPException(
            status_code=400, 
            detail=f"å‚è€ƒéŸ³é¢‘åºå·æ— æ•ˆ: {request.reference_audio_index}. æœ‰æ•ˆèŒƒå›´: 0-{len(REFERENCE_AUDIO_FILES)-1}"
        )
    
    # è·å–å‚è€ƒéŸ³é¢‘æ–‡ä»¶è·¯å¾„
    audio_prompt_path = REFERENCE_AUDIO_FILES[request.reference_audio_index]
    
    # æ£€æŸ¥å‚è€ƒéŸ³é¢‘æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(audio_prompt_path):
        raise HTTPException(
            status_code=500, 
            detail=f"å‚è€ƒéŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_prompt_path}"
        )
    
    print(f"ğŸ¤ å¼€å§‹è¯­éŸ³åˆæˆ:")
    print(f"   æ–‡æœ¬: {request.text}")
    print(f"   å‚è€ƒéŸ³é¢‘: {audio_prompt_path}")
    print(f"   å¿«é€Ÿæ¨ç†: {request.use_fast_inference}")
    
    try:
        # åˆ›å»ºä¸´æ—¶æ–‡ä»¶ï¼ˆä¸è‡ªåŠ¨åˆ é™¤ï¼‰
        temp_fd, temp_path = tempfile.mkstemp(suffix=".wav", prefix="tts_output_")
        os.close(temp_fd)  # å…³é—­æ–‡ä»¶æè¿°ç¬¦
        
        try:
            print(f"   ä¸´æ—¶è¾“å‡ºè·¯å¾„: {temp_path}")
            
            # å‡†å¤‡ç”Ÿæˆå‚æ•°
            generation_kwargs = {
                "do_sample": request.do_sample,
                "top_p": request.top_p,
                "top_k": request.top_k,
                "temperature": request.temperature,
                "length_penalty": request.length_penalty,
                "num_beams": request.num_beams,
                "repetition_penalty": request.repetition_penalty,
                "max_mel_tokens": request.max_mel_tokens,
            }
            
            # é€‰æ‹©æ¨ç†æ–¹æ³•
            if request.use_fast_inference:
                print("ğŸ”„ ä½¿ç”¨å¿«é€Ÿæ¨ç†æ¨¡å¼...")
                result_path = tts_model.infer_fast(
                    audio_prompt=audio_prompt_path,
                    text=request.text,
                    output_path=temp_path,
                    verbose=request.verbose,
                    max_text_tokens_per_sentence=request.max_text_tokens_per_sentence,
                    sentences_bucket_max_size=request.sentences_bucket_max_size,
                    **generation_kwargs
                )
            else:
                print("ğŸ”„ ä½¿ç”¨æ ‡å‡†æ¨ç†æ¨¡å¼...")
                result_path = tts_model.infer(
                    audio_prompt=audio_prompt_path,
                    text=request.text,
                    output_path=temp_path,
                    verbose=request.verbose,
                    max_text_tokens_per_sentence=request.max_text_tokens_per_sentence,
                    **generation_kwargs
                )
            
            print(f"   æ¨ç†è¿”å›è·¯å¾„: {result_path}")
            # æ£€æŸ¥ç”Ÿæˆæ˜¯å¦æˆåŠŸ
            if not result_path or not isinstance(result_path, str) or not os.path.exists(result_path):
                print(f"âŒ éŸ³é¢‘æ–‡ä»¶ç”Ÿæˆå¤±è´¥:")
                print(f"   è¿”å›è·¯å¾„: {result_path}")
                print(f"   è¾“å‡ºè·¯å¾„: {temp_path}")
                print(f"   è¾“å‡ºè·¯å¾„å­˜åœ¨: {os.path.exists(str(temp_path)) if temp_path else False}")
                if result_path:
                    print(f"   è¿”å›è·¯å¾„å­˜åœ¨: {os.path.exists(str(result_path))}")
                raise HTTPException(status_code=500, detail="éŸ³é¢‘ç”Ÿæˆå¤±è´¥ï¼šç”Ÿæˆçš„éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨")
            
            print(f"âœ… éŸ³é¢‘ç”ŸæˆæˆåŠŸ: {result_path}")
            
            # åˆ›å»ºè‡ªå®šä¹‰ FileResponse ç±»ï¼Œåœ¨å‘é€åè‡ªåŠ¨åˆ é™¤ä¸´æ—¶æ–‡ä»¶
            class TempFileResponse(FileResponse):
                def __init__(self, *args, **kwargs):
                    self.temp_file_path = kwargs.pop('temp_file_path', None)
                    super().__init__(*args, **kwargs)
                
                async def __call__(self, scope, receive, send):
                    try:
                        await super().__call__(scope, receive, send)
                    finally:
                        # åœ¨å“åº”å‘é€å®Œæˆååˆ é™¤ä¸´æ—¶æ–‡ä»¶
                        if self.temp_file_path and os.path.exists(self.temp_file_path):
                            try:
                                os.unlink(self.temp_file_path)
                                print(f"ğŸ—‘ï¸ ä¸´æ—¶æ–‡ä»¶å·²åˆ é™¤: {self.temp_file_path}")
                            except Exception as e:
                                print(f"âš ï¸ åˆ é™¤ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {e}")
            
            # è¿”å›ç”Ÿæˆçš„éŸ³é¢‘æ–‡ä»¶
            return TempFileResponse(
                result_path,
                media_type="audio/wav",
                filename=f"synthesized_{int(time.time())}.wav",
                headers={
                    "Content-Disposition": "attachment; filename=synthesized_audio.wav"
                },
                temp_file_path=result_path
            )
            
        except Exception as e:
            # å¦‚æœå‘ç”Ÿé”™è¯¯ï¼Œç¡®ä¿æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if os.path.exists(temp_path):
                try:
                    os.unlink(temp_path)
                except:
                    pass
            raise e
            
    except HTTPException:
        # é‡æ–°æŠ›å‡º HTTP å¼‚å¸¸
        raise
    except Exception as e:
        print(f"âŒ è¯­éŸ³åˆæˆè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"è¯­éŸ³åˆæˆå¤±è´¥: {str(e)}")


@app.on_event("startup")
async def startup_event():
    """åº”ç”¨å¯åŠ¨æ—¶åˆå§‹åŒ–æ¨¡å‹"""
    initialize_model()


@app.get("/")
async def root():
    """æ ¹è·¯å¾„ï¼Œè¿”å› API ä¿¡æ¯"""
    return {
        "message": "IndexTTS API æœåŠ¡è¿è¡Œä¸­",
        "version": "1.0.0",
        "status": "running",
        "model_loaded": tts_model is not None
    }


@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥æ¥å£"""
    return {
        "status": "healthy",
        "model_loaded": tts_model is not None,
        "timestamp": time.time()
    }


@app.post("/synthesize")
async def synthesize_speech(request: SynthesizeRequest):
    """
    è¯­éŸ³åˆæˆæ¥å£
    
    Args:
        request: åŒ…å«æ‰€æœ‰åˆæˆå‚æ•°çš„è¯·æ±‚ä½“
    
    Returns:
        åˆæˆçš„éŸ³é¢‘æ–‡ä»¶
    """
    return await _synthesize_speech_core(request)


@app.post("/synthesize_simple")
async def synthesize_speech_simple(request: SimpleSynthesizeRequest):
    """
    ç®€åŒ–çš„è¯­éŸ³åˆæˆæ¥å£ï¼Œä½¿ç”¨é»˜è®¤å‚æ•°
    é€‚åˆç®€å•çš„TTSè°ƒç”¨
    """
    # è½¬æ¢ä¸ºå®Œæ•´çš„è¯·æ±‚å¯¹è±¡
    full_request = SynthesizeRequest(
        text=request.text,
        reference_audio_index=request.reference_audio_index,
        use_fast_inference=False,
        verbose=False
    )
    return await _synthesize_speech_core(full_request)


@app.post("/synthesize_stream")
async def synthesize_stream(request: StreamSynthesizeRequest):
    """
    æµå¼è¯­éŸ³åˆæˆæ¥å£
    
    è¿”å›16bit PCMæ•°æ®æµï¼Œä¸åŒ…å«WAVå¤´
    é€‚åˆå®æ—¶éŸ³é¢‘å¤„ç†å’Œä½å»¶è¿Ÿåº”ç”¨
    
    Args:
        request: åŒ…å«åˆæˆå‚æ•°çš„è¯·æ±‚ä½“
    
    Returns:
        StreamingResponse: 16bit PCMéŸ³é¢‘æ•°æ®æµ
    """
    if tts_model is None:
        raise HTTPException(status_code=500, detail="æ¨¡å‹æœªåŠ è½½")
    
    if not request.text.strip():
        raise HTTPException(status_code=400, detail="æ–‡æœ¬ä¸èƒ½ä¸ºç©º")
    
    # éªŒè¯å‚è€ƒéŸ³é¢‘åºå·
    if request.reference_audio_index < 0 or request.reference_audio_index >= len(REFERENCE_AUDIO_FILES):
        raise HTTPException(
            status_code=400, 
            detail=f"å‚è€ƒéŸ³é¢‘åºå·æ— æ•ˆ: {request.reference_audio_index}. æœ‰æ•ˆèŒƒå›´: 0-{len(REFERENCE_AUDIO_FILES)-1}"
        )
    
    # è·å–å‚è€ƒéŸ³é¢‘æ–‡ä»¶è·¯å¾„
    audio_prompt_path = REFERENCE_AUDIO_FILES[request.reference_audio_index]
    
    # æ£€æŸ¥å‚è€ƒéŸ³é¢‘æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(audio_prompt_path):
        raise HTTPException(
            status_code=500, 
            detail=f"å‚è€ƒéŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_prompt_path}"
        )
    
    print(f"ğŸ¤ å¼€å§‹æµå¼è¯­éŸ³åˆæˆ:")
    print(f"   æ–‡æœ¬: {request.text}")
    print(f"   å‚è€ƒéŸ³é¢‘: {audio_prompt_path}")
    
    # å‡†å¤‡ç”Ÿæˆå‚æ•°
    generation_kwargs = {
        "do_sample": request.do_sample,
        "top_p": request.top_p,
        "top_k": request.top_k,
        "temperature": request.temperature,
        "length_penalty": request.length_penalty,
        "num_beams": request.num_beams,
        "repetition_penalty": request.repetition_penalty,
        "max_mel_tokens": request.max_mel_tokens,
    }
    
    def generate_pcm_stream():
        """ç”Ÿæˆ16bit PCMæ•°æ®æµçš„ç”Ÿæˆå™¨å‡½æ•°"""
        try:
            # è°ƒç”¨ infer_stream_pcm è·å–16bit PCMéŸ³é¢‘ç‰‡æ®µ
            assert tts_model is not None, "æ¨¡å‹å®ä¾‹ä¸åº”ä¸ºNone"
            for chunk_info in tts_model.infer_stream_pcm(
                audio_prompt=audio_prompt_path,
                text=request.text,
                verbose=request.verbose,
                max_text_tokens_per_sentence=request.max_text_tokens_per_sentence,
                **generation_kwargs
            ):
                # è·å–PCMå­—èŠ‚æ•°æ®
                pcm_bytes = chunk_info['audio_pcm_bytes']
                
                print(f"ğŸ“¦ ç”ŸæˆéŸ³é¢‘ç‰‡æ®µ: {len(pcm_bytes)} å­—èŠ‚, å¥å­ {chunk_info['sentence_index'] + 1}/{chunk_info['total_sentences']}")
                
                yield pcm_bytes
                
        except HTTPException:
            # é‡æ–°æŠ›å‡º HTTP å¼‚å¸¸
            raise
        except Exception as e:
            print(f"âŒ æµå¼è¯­éŸ³åˆæˆè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
            raise HTTPException(status_code=500, detail=f"æµå¼è¯­éŸ³åˆæˆå¤±è´¥: {str(e)}")
    
    # è¿”å›æµå¼å“åº”
    return StreamingResponse(
        generate_pcm_stream(),
        media_type="application/octet-stream",
        headers={
            "Content-Disposition": "attachment; filename=synthesized_audio.pcm",
            "X-Sample-Rate": "24000",  # é‡‡æ ·ç‡ä¿¡æ¯æ”¾åœ¨å¤´éƒ¨
            "X-Bit-Depth": "16",      # ä½æ·±åº¦ä¿¡æ¯
            "X-Channels": "1",        # å£°é“æ•°ä¿¡æ¯
        }
    )


@app.get("/test")
async def test_speech():
    """
    æµ‹è¯•è¯­éŸ³åˆæˆæ¥å£
    ä½¿ç”¨å›ºå®šæ–‡æœ¬"æ¬¢è¿ä½¿ç”¨TTSæœåŠ¡"è¿›è¡Œè¯­éŸ³åˆæˆæµ‹è¯•
    """
    test_text = "æ¬¢è¿ä½¿ç”¨TTSæœåŠ¡"
    
    # åˆ›å»ºæµ‹è¯•è¯·æ±‚
    test_request = SynthesizeRequest(
        text=test_text,
        reference_audio_index=0,
        use_fast_inference=True,
        verbose=False
    )
    
    return await _synthesize_speech_core(test_request)


@app.get("/reference_audios")
async def get_reference_audios():
    """è·å–å¯ç”¨çš„å‚è€ƒéŸ³é¢‘åˆ—è¡¨"""
    audio_list = []
    for i, audio_path in enumerate(REFERENCE_AUDIO_FILES):
        audio_info = {
            "index": i,
            "path": audio_path,
            "exists": os.path.exists(audio_path),
            "filename": os.path.basename(audio_path)
        }
        audio_list.append(audio_info)
    
    return {
        "reference_audios": audio_list,
        "total_count": len(REFERENCE_AUDIO_FILES)
    }


@app.get("/model_info")
async def get_model_info():
    """è·å–æ¨¡å‹ä¿¡æ¯"""
    if tts_model is None:
        raise HTTPException(status_code=500, detail="æ¨¡å‹æœªåŠ è½½")
    
    return {
        "model_loaded": True,
        "device": str(tts_model.device),
        "is_fp16": tts_model.is_fp16,
        "use_cuda_kernel": tts_model.use_cuda_kernel,
        "model_version": getattr(tts_model, 'model_version', None),
        "config_path": "checkpoints/config.yaml",
        "model_dir": tts_model.model_dir
    }


if __name__ == "__main__":
    # é€šè¿‡ start_api.sh è„šæœ¬å¯åŠ¨ï¼Œæ”¯æŒç«¯å£é…ç½®
    # ä¹Ÿå¯ä»¥ç›´æ¥è¿è¡Œ: uvicorn api_server:app --host 0.0.0.0 --port 8000
    print("æç¤ºï¼šå»ºè®®ä½¿ç”¨ ./start_api.sh å¯åŠ¨æœåŠ¡ï¼Œæ”¯æŒç«¯å£é…ç½®")
    print("æˆ–è€…ç›´æ¥ä½¿ç”¨: uvicorn api_server:app --host 0.0.0.0 --port 8000")
    
    # é»˜è®¤å¯åŠ¨
    uvicorn.run(
        "api_server:app",
        host="0.0.0.0",
        port=8000,
        reload=False,  # ç”Ÿäº§ç¯å¢ƒå»ºè®®è®¾ä¸º False
        workers=1      # TTS æ¨¡å‹é€šå¸¸ä¸æ”¯æŒå¤šè¿›ç¨‹ï¼Œä½¿ç”¨å•ä¸ª worker
    ) 